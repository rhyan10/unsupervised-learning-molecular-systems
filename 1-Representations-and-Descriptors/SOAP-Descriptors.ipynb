{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6af903c",
   "metadata": {},
   "source": [
    "# Smooth Overlap of Atomic Positions (SOAP) Descriptors\n",
    "Prominant 3D representations for molecules include the [Coulomb matrix](./Coulomb-Matrices.ipynb), Smooth Overlap of Atomic Positions (SOAP), Atom-Centered Symmetry Functions (ACSF), the atomic cluster expansion (ACE), atomic features built by the hierarchically interacting particle neural network (HIP-NN), and the N-body iterative contraction of equivariants (NICE).\n",
    "\n",
    "Here, we demonstrate how to generate SOAP descriptors for molecules.\n",
    "\n",
    "We will use the same kernel as in the [Fingerprints and SMILES](./1-Fingerprints-and-SMILES.ipynb) notebook, and the QM7 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb40ac0a",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "This particular notebook uses `asaplib`, a library containing \"Automatic Selection And Prediction\" tools for materials and molecules. It provides tools for analyzing and visualizing atomic simulation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dfd70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from asaplib.data import ASAPXYZ\n",
    "\n",
    "# Import QM7 coordinates using `asaplib`\n",
    "asapxyz = ASAPXYZ('../data/qm7.xyz', periodic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "235dea55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from asaplib.hypers import universal_soap_hyper\n",
    "\n",
    "global_species = asapxyz.get_global_species()\n",
    "\n",
    "universal_soap = 'minimal'\n",
    "soap_spec = universal_soap_hyper(global_species, universal_soap, dump=True)\n",
    "\n",
    "soap_spec\n",
    "\n",
    "for k in soap_spec.keys():\n",
    "    soap_spec[k]['rbf'] = 'gto'\n",
    "    soap_spec[k]['crossover'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ada008",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(global_species)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8caa42cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the parameters\n",
    "\n",
    "reducer_spec = {'reducer1': {\n",
    "                          'reducer_type': 'average', # [average], [sum], [moment_average], [moment_sum]\n",
    "                          'element_wise': False}\n",
    "               }\n",
    "\n",
    "desc_spec = {'avgsoap': {\n",
    "                  'atomic_descriptor': soap_spec,\n",
    "                  'reducer_function': reducer_spec}\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a77a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute descriptors for the whole structures\n",
    "asapxyz.compute_global_descriptors(desc_spec_dict=desc_spec,\n",
    "                                    sbs=[],\n",
    "                                    keep_atomic=False, # set to True to keep the atomic descriptors\n",
    "                                    tag='qm7',\n",
    "                                    n_process=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5539c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = asapxyz.fetch_computed_descriptors(['avgsoap'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f8f88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b689874",
   "metadata": {},
   "outputs": [],
   "source": [
    "fy = 'atomization_energy'\n",
    "y_train = asapxyz.get_property(fy) #, extensive = 'True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8270ff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "X_train = torch.from_numpy(X_train).float()\n",
    "\n",
    "# On some computers the explicit cast to .float() is\n",
    "# necessary\n",
    "y_train = torch.from_numpy(y_train).float()\n",
    "\n",
    "dataset = TensorDataset(X_train, y_train)\n",
    "\n",
    "train_ds, val_ds = random_split(dataset, [0.9, 0.1])\n",
    "\n",
    "batch_size = 1\n",
    "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecfd9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NNModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(input_size, hidden_size)\n",
    "        self.layer2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = nn.Sigmoid()(x)\n",
    "        x = self.layer2(x)\n",
    "        return x\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "hidden_size = 8\n",
    "output_size = 1\n",
    "\n",
    "nnmodel = NNModel(input_size, hidden_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39148eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb68040e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.00001\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction='mean')\n",
    "\n",
    "optimizer = torch.optim.Adam(nnmodel.parameters(), lr=learning_rate)\n",
    "\n",
    "num_epochs = 100\n",
    "log_epochs = 1\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for x_batch, y_batch in train_loader:\n",
    "        # 1. Generate predictions\n",
    "        pred = nnmodel(x_batch)[:, 0]\n",
    "\n",
    "        # 2. Calculate loss\n",
    "        loss = loss_fn(pred, y_batch)\n",
    "\n",
    "        # 3. Compute gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # 4. Update parameters using gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # 5. Reset the gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    if epoch % log_epochs==0:\n",
    "        print(f'Epoch {epoch}  Loss {loss.item():.4e}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff6fb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = fig.add_subplot(1, 1, 1)\n",
    "ax.plot(loss_hist, lw=3)\n",
    "ax.set_title('Training loss', size=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5890e22",
   "metadata": {},
   "source": [
    "## TipsðŸ’¡\n",
    "\n",
    "### TODO\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
